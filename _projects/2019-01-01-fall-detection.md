---
title: "Fall Detection Research By Egocentric Cameras"
excerpt: "Designed and built the EGOFalls multimodal fall detection benchmark dataset from an egocentric perspective, now open-sourced and adopted by multiple international teams."
collection: projects
date: 2019-01-01
---

**Duration**: 2019 -- 2024

Designed and built the EGOFalls multimodal fall detection benchmark dataset from an egocentric perspective, now open-sourced and adopted by multiple international teams. Proposed a visual-audio fusion framework combining Event Camera and Spiking Neural Network technologies, achieving high accuracy across varied environmental and lighting conditions.

## EGOFALLS Dataset

EGOFALLS is a visual-audio dataset and benchmark for fall detection using egocentric cameras.

![Examples of 12 activities, including four kinds of falls and eight kinds of non-falls.](https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/fc7cc58f-1c8e-4c08-8da5-4b9caef27134)

### Data Collection

- **Date**: 2018 -- 2022
- **Location**: Groningen, Netherlands
- **Equipment**: OnReal G1 (RGB), CAMMHD Bodycams (RGB and Infrared)
- **Subjects**: 14 (12 male, 2 female), age 20--60
- **Camera Position**: Neck and Waist
- **Environment**: Indoor and outdoor
- **Modalities**: Vision and Audio

### Dataset Structure

Quantity and type of video clips per participant (C1 and C2 refer to camera 1 and camera 2):

<img width="1108" alt="Data overview" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/f855201d-8b08-472e-bba5-533b0d43045f">

The dataset is organized within individual directories corresponding to each subject:

<img width="786" alt="Subject directories" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/63960f60-3b3e-4292-9292-d83c25f90076">

The data follows a hierarchical structure:

<img width="712" alt="Hierarchical structure" src="https://github.com/Xueyi-Wang/EGOFALLS/assets/55747740/1be4c4ab-fb3f-4107-abc9-74667e671ea9">

### Links

- [GitHub Repository](https://github.com/Xueyi-Wang/EGOFALLS)
